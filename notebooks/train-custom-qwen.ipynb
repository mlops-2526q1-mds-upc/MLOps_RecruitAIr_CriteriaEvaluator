{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f12c8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mirxm\\Storage\\Work\\MDS\\S3\\MLOps\\CriteriaEvaluator\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from recruitair.modeling.custom_qwen import customize_qwen_model, freeze_custom_qwen_backbone\n",
    "import torch\n",
    "from torch import nn\n",
    "import contextlib\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import time\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "from recruitair.modeling.tokenize import ResumeAndCriteriaTokenizer\n",
    "import mlflow\n",
    "\n",
    "# os.environ[\"STORE_INPUT_TENSORS\"] = \"true\" # Uncomment this line to store input tensors that cause OOM errors\n",
    "# os.environ[\"STORE_MEMORY_SNAPSHOTS\"] = \"true\" # Uncomment this line to store CUDA memory snapshots on OOM errors\n",
    "# Use tool https://docs.pytorch.org/memory_viz to analyze the memory snapshots\n",
    "os.environ[\"MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING\"] = \"true\"\n",
    "mlflow.set_tracking_uri(\"http://nattech.fib.upc.edu:40380/\")\n",
    "mlflow.set_experiment(\"criteria-evaluation/custom-qwen-finetune\")\n",
    "mlflow.pytorch.autolog()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "143be879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained model\n",
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "original_model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=\"auto\", device_map=\"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = customize_qwen_model(original_model)\n",
    "freeze_custom_qwen_backbone(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deaac442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and testing datasets from \"data/processed/train.jsonl\" and \"data/processed/validation.jsonl\"\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_json(\"../data/processed/train.jsonl\", lines=True, encoding=\"utf-8\")\n",
    "val_df = pd.read_json(\"../data/processed/validation.jsonl\", lines=True, encoding=\"utf-8\")\n",
    "\n",
    "# Convert the DataFrames to PyTorch Datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class CriteriaDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        return row[\"resume\"], row[\"criteria\"], row[\"score\"] / 10.0  # Normalize score to [0, 1]\n",
    "\n",
    "\n",
    "train_dataset = CriteriaDataset(train_df)\n",
    "val_dataset = CriteriaDataset(val_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94cee643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer only for head\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3, weight_decay=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "custom_tokenizer = ResumeAndCriteriaTokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a428bcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/10 21:28:12 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/10/10 21:28:12 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "2025/10/10 22:14:06 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/10/10 22:14:06 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 loss: 0.3272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/10 22:32:13 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/10/10 22:32:13 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "2025/10/10 22:32:13 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run custom-qwen-finetune-validation at: http://nattech.fib.upc.edu:40380/#/experiments/2/runs/1763dc3643cb4f1faca0fc242dac7da3\n",
      "üß™ View experiment at: http://nattech.fib.upc.edu:40380/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/10 22:32:17 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cu126) contains a local version label (+cu126). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/10/10 22:32:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Successfully registered model 'custom-qwen-finetuned'.\n",
      "2025/10/10 22:32:30 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: custom-qwen-finetuned, version 1\n",
      "Created version '1' of model 'custom-qwen-finetuned'.\n",
      "2025/10/10 23:22:18 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/10/10 23:22:18 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 loss: 0.3272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/10 23:35:35 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run custom-qwen-finetune-validation at: http://nattech.fib.upc.edu:40380/#/experiments/2/runs/b0bdacf339464739af1cbb1ff9ab65b5\n",
      "üß™ View experiment at: http://nattech.fib.upc.edu:40380/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/10 23:35:35 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "2025/10/10 23:35:35 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/10 23:35:39 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cu126) contains a local version label (+cu126). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/10/10 23:36:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'custom-qwen-finetuned' already exists. Creating a new version of this model...\n",
      "2025/10/10 23:36:11 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: custom-qwen-finetuned, version 2\n",
      "Created version '2' of model 'custom-qwen-finetuned'.\n",
      "2025/10/11 00:28:13 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/10/11 00:28:13 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 loss: 0.3272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/11 00:41:21 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run custom-qwen-finetune-validation at: http://nattech.fib.upc.edu:40380/#/experiments/2/runs/5c34360979504f35806c115baf2f876e\n",
      "üß™ View experiment at: http://nattech.fib.upc.edu:40380/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/11 00:41:21 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "2025/10/11 00:41:21 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/11 00:41:26 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cu126) contains a local version label (+cu126). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/10/11 00:41:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'custom-qwen-finetuned' already exists. Creating a new version of this model...\n",
      "2025/10/11 00:41:38 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: custom-qwen-finetuned, version 3\n",
      "Created version '3' of model 'custom-qwen-finetuned'.\n",
      "2025/10/11 01:33:06 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/10/11 01:33:06 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 loss: 0.3272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/11 01:46:21 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run custom-qwen-finetune-validation at: http://nattech.fib.upc.edu:40380/#/experiments/2/runs/607d667718d84e1f9d2a4ccc5c878d94\n",
      "üß™ View experiment at: http://nattech.fib.upc.edu:40380/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/11 01:46:21 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "2025/10/11 01:46:21 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/11 01:46:26 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cu126) contains a local version label (+cu126). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/10/11 01:46:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'custom-qwen-finetuned' already exists. Creating a new version of this model...\n",
      "2025/10/11 01:46:39 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: custom-qwen-finetuned, version 4\n",
      "Created version '4' of model 'custom-qwen-finetuned'.\n",
      "2025/10/11 02:36:43 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/10/11 02:36:43 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 loss: 0.2978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.2909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/11 02:49:43 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run custom-qwen-finetune-validation at: http://nattech.fib.upc.edu:40380/#/experiments/2/runs/0d2a986341884d11b8070b8649424173\n",
      "üß™ View experiment at: http://nattech.fib.upc.edu:40380/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/11 02:49:43 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "2025/10/11 02:49:43 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/11 02:49:48 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cu126) contains a local version label (+cu126). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/10/11 02:50:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'custom-qwen-finetuned' already exists. Creating a new version of this model...\n",
      "2025/10/11 02:50:21 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: custom-qwen-finetuned, version 5\n",
      "Created version '5' of model 'custom-qwen-finetuned'.\n",
      "2025/10/11 02:50:22 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run custom-qwen-finetune at: http://nattech.fib.upc.edu:40380/#/experiments/2/runs/fffdb50c061246fcbcff1eb1cc1fc51e\n",
      "üß™ View experiment at: http://nattech.fib.upc.edu:40380/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/11 02:50:22 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "if os.getenv(\"STORE_INPUT_TENSORS\", \"false\").lower() == \"true\":\n",
    "    pathlib.Path(\"../data/raw/input-data\").mkdir(parents=True, exist_ok=True)\n",
    "if os.getenv(\"STORE_INPUT_TENSORS\", \"false\").lower() == \"true\":\n",
    "    pathlib.Path(\"../data/raw/input-data\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "num_epochs = 5\n",
    "with mlflow.start_run(run_name=\"custom-qwen-finetune\"):\n",
    "    mlflow.log_params(\n",
    "        {\n",
    "            \"num_epochs\": num_epochs,\n",
    "            \"optimizer\": \"Adam\",\n",
    "            \"optimizer/Adam/learning_rate\": 1e-3,\n",
    "            \"optimizer/Adam/weight_decay\": 1e-4,\n",
    "            \"criterion\": \"MSELoss\",\n",
    "            \"batch_size\": 8,\n",
    "            \"original-model\": model_name,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    train_start = time.monotonic()\n",
    "\n",
    "    torch.cuda.memory._record_memory_history()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.monotonic()\n",
    "        model.train()\n",
    "        model.backbone.eval()\n",
    "        model.head.train()\n",
    "        running_loss = 0.0\n",
    "        bar = tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False, unit=\"batch\")\n",
    "        for resume_batch, criteria_batch, score_batch in train_loader:\n",
    "            padded_input_tokens, attention_mask = custom_tokenizer(resume_batch, criteria_batch)\n",
    "            padded_input_tokens = padded_input_tokens.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            score_batch = score_batch.type(torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if os.getenv(\"STORE_INPUT_TENSORS\", \"false\").lower() == \"true\":\n",
    "                # Save the input values that caused the error for debugging\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"padded_input_tokens\": padded_input_tokens,\n",
    "                        \"attention_mask\": attention_mask,\n",
    "                        \"score_batch\": score_batch,\n",
    "                        \"resume_batch\": resume_batch,\n",
    "                        \"criteria_batch\": criteria_batch,\n",
    "                        \"epoch\": epoch,\n",
    "                        \"batch_index\": bar.n,\n",
    "                    },\n",
    "                    f\"../data/raw/input-data/epoch{epoch+1}-batch{bar.n + 1}-inputs.pth\",\n",
    "                )\n",
    "\n",
    "            try:\n",
    "                preds = model(input_ids=padded_input_tokens, attention_mask=attention_mask)\n",
    "            except Exception as e:\n",
    "                if os.getenv(\"STORE_INPUT_TENSORS\", \"false\").lower() == \"true\":\n",
    "                    with contextlib.suppress(Exception):\n",
    "                        torch.cuda.memory._dump_snapshot(\n",
    "                            f\"../data/raw/cuda-mem-snapshots/epoch{epoch+1}-batch{bar.n + 1}-error.pickle\"\n",
    "                        )\n",
    "                raise e from e\n",
    "\n",
    "            loss = criterion(preds, score_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * len(resume_batch)\n",
    "            # Update progress bar's description with current loss\n",
    "            bar.set_postfix(loss=loss.item())\n",
    "            bar.update(1)\n",
    "            if os.getenv(\"STORE_MEMORY_SNAPSHOTS\", \"false\").lower() == \"true\":\n",
    "                try:\n",
    "                    torch.cuda.memory._dump_snapshot(\n",
    "                        f\"../data/raw/cuda-mem-snapshots/epoch{epoch+1}-batch{bar.n}.pickle\"\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not dump CUDA memory snapshot: {e}\")\n",
    "        bar.close()\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        mlflow.log_metric(\"epoch_duration_seconds\", time.monotonic() - epoch_start, step=epoch)\n",
    "        mlflow.log_metric(\"train_loss\", epoch_loss, step=epoch)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} loss: {epoch_loss:.4f}\")\n",
    "        # Validation\n",
    "        with mlflow.start_run(run_name=\"custom-qwen-finetune-validation\", nested=True):\n",
    "            validation_start = time.monotonic()\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            bar = tqdm(total=len(val_loader), desc=f\"Validation {epoch+1}/{num_epochs}\", leave=False, unit=\"batch\")\n",
    "            with torch.no_grad():\n",
    "                for resume_batch, criteria_batch, score_batch in val_loader:\n",
    "                    padded_input_tokens, attention_mask = custom_tokenizer(resume_batch, criteria_batch)\n",
    "                    padded_input_tokens = padded_input_tokens.to(device)\n",
    "                    attention_mask = attention_mask.to(device)\n",
    "                    score_batch = score_batch.type(torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "                    preds = model(input_ids=padded_input_tokens, attention_mask=attention_mask)\n",
    "                    loss = criterion(preds, score_batch)\n",
    "                    val_loss += loss.item() * len(resume_batch)\n",
    "                    bar.set_postfix(loss=loss.item())\n",
    "                    bar.update(1)\n",
    "            bar.close()\n",
    "            val_epoch_loss = val_loss / len(val_loader.dataset)\n",
    "            print(f\"Validation loss: {val_epoch_loss:.4f}\")\n",
    "            mlflow.log_metric(\"validation_loss\", val_epoch_loss, step=epoch)\n",
    "            mlflow.log_metric(\"validation_duration_seconds\", time.monotonic() - validation_start, step=epoch)\n",
    "        mlflow.pytorch.log_model(\n",
    "            model, artifact_path=\"model\", registered_model_name=\"custom-qwen-finetuned\", step=epoch\n",
    "        )\n",
    "    mlflow.log_metric(\"total_training_duration_seconds\", time.monotonic() - train_start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recruitair (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
