{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f12c8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mirxm\\Storage\\Work\\MDS\\S3\\MLOps\\CriteriaEvaluator\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from recruitair.modeling.custom_qwen import customize_qwen_model, freeze_custom_qwen_backbone\n",
    "import torch\n",
    "from torch import nn\n",
    "import contextlib\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import time\n",
    "import pathlib\n",
    "from codecarbon import EmissionsTracker\n",
    "from tqdm import tqdm\n",
    "from recruitair.modeling.tokenize import ResumeAndCriteriaTokenizer\n",
    "import mlflow\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "# os.environ[\"STORE_INPUT_TENSORS\"] = \"true\" # Uncomment this line to store input tensors that cause OOM errors\n",
    "# os.environ[\"STORE_MEMORY_SNAPSHOTS\"] = \"true\" # Uncomment this line to store CUDA memory snapshots on OOM errors\n",
    "# Use tool https://docs.pytorch.org/memory_viz to analyze the memory snapshots\n",
    "os.environ[\"MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING\"] = \"true\"\n",
    "os.environ[\"codecarbon_log_level\"] = \"WARNING\"  # Disable most of the loggings\n",
    "mlflow.set_tracking_uri(\"http://nattech.fib.upc.edu:40380/\")\n",
    "mlflow.set_experiment(\"criteria-evaluation/custom-qwen-finetune\")\n",
    "mlflow.pytorch.autolog()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb44e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1\n",
    "ORIGINAL_MODEL_NAME = \"Qwen/Qwen3-0.6B\"\n",
    "BATCH_SIZE = 8\n",
    "ADAM_LEARNING_RATE = 1e-3\n",
    "ADAM_WEIGHT_DECAY = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "143be879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained model\n",
    "original_model = AutoModelForCausalLM.from_pretrained(ORIGINAL_MODEL_NAME, torch_dtype=\"auto\", device_map=\"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(ORIGINAL_MODEL_NAME)\n",
    "model = customize_qwen_model(original_model)\n",
    "freeze_custom_qwen_backbone(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deaac442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and testing datasets from \"data/processed/train.jsonl\" and \"data/processed/validation.jsonl\"\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_json(\"../data/processed/train.jsonl\", lines=True, encoding=\"utf-8\")\n",
    "val_df = pd.read_json(\"../data/processed/validation.jsonl\", lines=True, encoding=\"utf-8\")\n",
    "\n",
    "# Convert the DataFrames to PyTorch Datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class CriteriaDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        return row[\"resume\"], row[\"criteria\"], row[\"score\"] / 10.0  # Normalize score to [0, 1]\n",
    "\n",
    "\n",
    "train_dataset = CriteriaDataset(train_df)\n",
    "val_dataset = CriteriaDataset(val_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94cee643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer only for head\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), lr=ADAM_LEARNING_RATE, weight_decay=ADAM_WEIGHT_DECAY\n",
    ")\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "custom_tokenizer = ResumeAndCriteriaTokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a428bcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 01:09:50 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "[codecarbon WARNING @ 01:09:50] Multiple instances of codecarbon are allowed to run at the same time.\n",
      "[codecarbon WARNING @ 01:09:51] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
      " Windows OS detected: Please install Intel Power Gadget to measure CPU\n",
      "\n",
      "[codecarbon WARNING @ 01:09:51] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 01:09:59 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 747.04it/s] \n",
      "2025/10/13 01:10:03 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cu126) contains a local version label (+cu126). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/10/13 01:10:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'custom-qwen-finetuned' already exists. Creating a new version of this model...\n",
      "2025/10/13 01:10:19 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: custom-qwen-finetuned, version 15\n",
      "Created version '15' of model 'custom-qwen-finetuned'.\n",
      "2025/10/13 01:10:19 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/10/13 01:10:19 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run custom-qwen-finetune at: http://nattech.fib.upc.edu:40380/#/experiments/2/runs/ae57ddc8ff964449ba2466934a1162de\n",
      "ðŸ§ª View experiment at: http://nattech.fib.upc.edu:40380/#/experiments/2\n"
     ]
    }
   ],
   "source": [
    "if os.getenv(\"STORE_INPUT_TENSORS\", \"false\").lower() == \"true\":\n",
    "    pathlib.Path(\"../data/raw/input-data\").mkdir(parents=True, exist_ok=True)\n",
    "if os.getenv(\"STORE_INPUT_TENSORS\", \"false\").lower() == \"true\":\n",
    "    pathlib.Path(\"../data/raw/input-data\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with mlflow.start_run(run_name=\"custom-qwen-finetune\") as run:\n",
    "    mlflow.log_params(\n",
    "        {\n",
    "            \"original_model\": ORIGINAL_MODEL_NAME,\n",
    "            \"num_epochs\": NUM_EPOCHS,\n",
    "            \"optimizer\": \"Adam\",\n",
    "            \"optimizer/Adam/learning_rate\": ADAM_LEARNING_RATE,\n",
    "            \"optimizer/Adam/weight_decay\": ADAM_WEIGHT_DECAY,\n",
    "            \"criterion\": \"MSELoss\",\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"original-model\": ORIGINAL_MODEL_NAME,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    train_start = time.monotonic()\n",
    "\n",
    "    tracker = EmissionsTracker(measure_power_secs=1, tracking_mode=\"process\", save_to_file=False)\n",
    "    torch.cuda.memory._record_memory_history()\n",
    "    tracker.start()\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        epoch_start = time.monotonic()\n",
    "        model.train()\n",
    "        model.backbone.eval()\n",
    "        model.head.train()\n",
    "        running_loss = 0.0\n",
    "        bar = tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\", leave=False, unit=\"batch\")\n",
    "        for resume_batch, criteria_batch, score_batch in train_loader:\n",
    "            encoded_inputs = custom_tokenizer(\n",
    "                resume_batch, criteria_batch, padding=True, return_tensors=\"pt\", padding_side=\"left\"\n",
    "            ).to(device)\n",
    "            score_batch = score_batch.type(torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if os.getenv(\"STORE_INPUT_TENSORS\", \"false\").lower() == \"true\":\n",
    "                # Save the input values that caused the error for debugging\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"encoded_inputs\": encoded_inputs,\n",
    "                        \"score_batch\": score_batch,\n",
    "                        \"resume_batch\": resume_batch,\n",
    "                        \"criteria_batch\": criteria_batch,\n",
    "                        \"epoch\": epoch,\n",
    "                        \"batch_index\": bar.n,\n",
    "                    },\n",
    "                    f\"../data/raw/input-data/epoch{epoch+1}-batch{bar.n + 1}-inputs.pth\",\n",
    "                )\n",
    "\n",
    "            try:\n",
    "                preds = model(**encoded_inputs)\n",
    "            except Exception as e:\n",
    "                if os.getenv(\"STORE_INPUT_TENSORS\", \"false\").lower() == \"true\":\n",
    "                    with contextlib.suppress(Exception):\n",
    "                        torch.cuda.memory._dump_snapshot(\n",
    "                            f\"../data/raw/cuda-mem-snapshots/epoch{epoch+1}-batch{bar.n + 1}-error.pickle\"\n",
    "                        )\n",
    "                raise e from e\n",
    "\n",
    "            loss = criterion(preds, score_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * len(resume_batch)\n",
    "            # Update progress bar's description with current loss\n",
    "            bar.set_postfix(loss=loss.item())\n",
    "            bar.update(1)\n",
    "            if os.getenv(\"STORE_MEMORY_SNAPSHOTS\", \"false\").lower() == \"true\":\n",
    "                try:\n",
    "                    torch.cuda.memory._dump_snapshot(\n",
    "                        f\"../data/raw/cuda-mem-snapshots/epoch{epoch+1}-batch{bar.n}.pickle\"\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not dump CUDA memory snapshot: {e}\")\n",
    "        bar.close()\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        mlflow.log_metric(\"epoch_duration_seconds\", time.monotonic() - epoch_start, step=epoch)\n",
    "        mlflow.log_metric(\"train_loss\", epoch_loss, step=epoch)\n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS} loss: {epoch_loss:.4f}\")\n",
    "        # Validation\n",
    "        validation_start = time.monotonic()\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        bar = tqdm(total=len(val_loader), desc=f\"Validation {epoch+1}/{NUM_EPOCHS}\", leave=False, unit=\"batch\")\n",
    "        with torch.no_grad():\n",
    "            for resume_batch, criteria_batch, score_batch in val_loader:\n",
    "                encoded_inputs = custom_tokenizer(\n",
    "                    resume_batch, criteria_batch, padding=True, return_tensors=\"pt\", padding_side=\"left\"\n",
    "                ).to(device)\n",
    "                score_batch = score_batch.type(torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "                preds = model(**encoded_inputs)\n",
    "                loss = criterion(preds, score_batch)\n",
    "                val_loss += loss.item() * len(resume_batch)\n",
    "                bar.set_postfix(loss=loss.item())\n",
    "                bar.update(1)\n",
    "        bar.close()\n",
    "        val_epoch_loss = val_loss / len(val_loader.dataset)\n",
    "        print(f\"Validation loss: {val_epoch_loss:.4f}\")\n",
    "        mlflow.log_metric(\"validation_loss\", val_epoch_loss, step=epoch)\n",
    "        mlflow.log_metric(\"validation_duration_seconds\", time.monotonic() - validation_start, step=epoch)\n",
    "\n",
    "    mlflow.log_metric(\"total_training_duration_seconds\", time.monotonic() - train_start)\n",
    "    tracker.stop()\n",
    "    all_metrics = tracker.final_emissions_data.values\n",
    "    num_metrics = {f\"emissions-tracker/{k}\": v for k, v in all_metrics.items() if isinstance(v, (int, float))}\n",
    "    mlflow.log_metrics(num_metrics, run_id=run.info.run_id)\n",
    "    # Log the model and the tokenizer\n",
    "    with TemporaryDirectory() as tmpdir:\n",
    "        tokenizer_dir = os.path.join(tmpdir, \"tokenizer\")\n",
    "        custom_tokenizer.save_pretrained(tokenizer_dir)\n",
    "        mlflow.pytorch.log_model(\n",
    "            model,\n",
    "            artifact_path=\"model\",\n",
    "            registered_model_name=\"custom-qwen-finetuned\",\n",
    "            step=epoch,\n",
    "            extra_files=[tokenizer_dir],\n",
    "            run_id=run.info.run_id,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recruitair (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
