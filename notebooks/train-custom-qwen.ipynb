{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f12c8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mirxm\\Storage\\Work\\MDS\\S3\\MLOps\\CriteriaEvaluator\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from recruitair.modeling.custom_qwen import customize_qwen_model, freeze_custom_qwen_backbone\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from recruitair.modeling.tokenize import ResumeAndCriteriaTokenizer\n",
    "import mlflow\n",
    "\n",
    "os.environ[\"MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING\"] = \"true\"\n",
    "mlflow.set_tracking_uri(\"http://nattech.fib.upc.edu:40380/\")\n",
    "mlflow.set_experiment(\"criteria-evaluation/custom-qwen-finetune\")\n",
    "mlflow.pytorch.autolog()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "143be879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained model\n",
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "original_model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=\"auto\", device_map=\"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = customize_qwen_model(original_model)\n",
    "freeze_custom_qwen_backbone(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deaac442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and testing datasets from \"data/processed/train.jsonl\" and \"data/processed/validation.jsonl\"\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_json(\"../data/processed/train.jsonl\", lines=True, encoding=\"utf-8\")\n",
    "val_df = pd.read_json(\"../data/processed/validation.jsonl\", lines=True, encoding=\"utf-8\")\n",
    "\n",
    "# Convert the DataFrames to PyTorch Datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class CriteriaDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        return row[\"resume\"], row[\"criteria\"], row[\"score\"] / 5.0  # Normalize score to [0, 1]\n",
    "\n",
    "\n",
    "train_dataset = CriteriaDataset(train_df)\n",
    "val_dataset = CriteriaDataset(val_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94cee643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer only for head\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3, weight_decay=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "custom_tokenizer = ResumeAndCriteriaTokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a428bcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/09 00:55:57 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/10/09 00:55:57 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "Epoch 1/5:   2%|‚ñè         | 7/381 [00:34<32:55,  5.28s/batch, loss=0.38] "
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "with mlflow.start_run(run_name=\"custom-qwen-finetune\"):\n",
    "    mlflow.log_params(\n",
    "        {\n",
    "            \"num_epochs\": num_epochs,\n",
    "            \"optimizer\": \"Adam\",\n",
    "            \"optimizer/Adam/learning_rate\": 1e-3,\n",
    "            \"optimizer/Adam/weight_decay\": 1e-4,\n",
    "            \"criterion\": \"MSELoss\",\n",
    "            \"batch_size\": 8,\n",
    "            \"original-model\": model_name,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    train_start = time.monotonic()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.monotonic()\n",
    "        model.train()\n",
    "        model.backbone.eval()\n",
    "        model.head.train()\n",
    "        running_loss = 0.0\n",
    "        bar = tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False, unit=\"batch\")\n",
    "        for resume_batch, criteria_batch, score_batch in train_loader:\n",
    "            padded_input_tokens, attention_mask = custom_tokenizer(resume_batch, criteria_batch)\n",
    "            padded_input_tokens = padded_input_tokens.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            score_batch = score_batch.type(torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(\n",
    "                input_ids=padded_input_tokens, attention_mask=attention_mask\n",
    "            )  # forward: frozen backbone -> trainable head\n",
    "            loss = criterion(preds, score_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * len(resume_batch)\n",
    "            # Update progress bar's description with current loss\n",
    "            bar.set_postfix(loss=loss.item())\n",
    "            bar.update(1)\n",
    "        bar.close()\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        mlflow.log_metric(\"epoch_duration_seconds\", time.monotonic() - epoch_start, step=epoch)\n",
    "        mlflow.log_metric(\"train_loss\", epoch_loss, step=epoch)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} loss: {epoch_loss:.4f}\")\n",
    "        # Validation\n",
    "        with mlflow.start_run(run_name=\"custom-qwen-finetune-validation\", nested=True):\n",
    "            validation_start = time.monotonic()\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            bar = tqdm(total=len(val_loader), desc=f\"Validation {epoch+1}/{num_epochs}\", leave=False, unit=\"batch\")\n",
    "            with torch.no_grad():\n",
    "                for resume_batch, criteria_batch, score_batch in val_loader:\n",
    "                    padded_input_tokens, attention_mask = custom_tokenizer(resume_batch, criteria_batch)\n",
    "                    padded_input_tokens = padded_input_tokens.to(device)\n",
    "                    attention_mask = attention_mask.to(device)\n",
    "                    score_batch = score_batch.type(torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "                    preds = model(input_ids=padded_input_tokens, attention_mask=attention_mask)\n",
    "                    loss = criterion(preds, score_batch)\n",
    "                    val_loss += loss.item() * len(resume_batch)\n",
    "                    bar.set_postfix(loss=loss.item())\n",
    "                    bar.update(1)\n",
    "            bar.close()\n",
    "            val_epoch_loss = val_loss / len(val_loader.dataset)\n",
    "            print(f\"Validation loss: {val_epoch_loss:.4f}\")\n",
    "            mlflow.log_metric(\"validation_loss\", val_epoch_loss, step=epoch)\n",
    "            mlflow.log_metric(\"validation_duration_seconds\", time.monotonic() - validation_start, step=epoch)\n",
    "        mlflow.pytorch.log_model(\n",
    "            model, artifact_path=\"model\", registered_model_name=\"custom-qwen-finetuned\", step=epoch\n",
    "        )\n",
    "    mlflow.log_metric(\"total_training_duration_seconds\", time.monotonic() - train_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a6a9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recruitair (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
